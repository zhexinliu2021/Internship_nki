{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8db9bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1133ef19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tools' from '/Users/jerryliu/jerry_jupyter/internship/tools.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd; import numpy as np \n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from functools import reduce\n",
    "import importlib\n",
    "from tools import write_file\n",
    "import multiprocessing\n",
    "import tools\n",
    "import importlib\n",
    "importlib.reload(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e3c9f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load four mutation files.\n",
    "path = '/Users/jerryliu/Documents/Vu_uva/internship/CCLE/mutation_files/'\n",
    "file_list = ['damaging','hotspot','nonconserving','otherconserving']\n",
    "drug_path = '/Users/jerryliu/Documents/Vu_uva/internship/CCLE/primary-screen-replicate-collapsed-logfold-change.csv'\n",
    "out_path = '/Users/jerryliu/jerry_jupyter/internship/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86230904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read drug sensitivity files. \n",
    "def read_drug(drug_path):\n",
    "    drug_data = pd.read_csv(drug_path)\n",
    "    drug_data = drug_data.set_index(drug_data.columns[0])\n",
    "    return(drug_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0521ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to merge two mutation files.\n",
    "def merge_mt(m_f1, m_f2, drug_id, gene_filter = False):\n",
    "    # input: dataframe with index as cell line id. \n",
    "    # output: merged dataframe\n",
    "    #cell lines: m_f1 & m_f2;  cancer genes: m_f1 | m_f2.\n",
    "    if not gene_filter:\n",
    "        cl_id = set.intersection(set(m_f1.index), set(m_f2.index), set(drug_id))\n",
    "    else:\n",
    "        cl_id = set.intersection(set(m_f1.index), set(m_f2.index))\n",
    "        \n",
    "    gene_id = set.union(set(m_f1.columns), set(m_f2.columns))\n",
    "\n",
    "    m_f1 = m_f1.reindex(cl_id, columns = gene_id, fill_value = 0 )\n",
    "    m_f2 = m_f2.reindex(cl_id, columns = gene_id, fill_value = 0)\n",
    "    #combine the two files.\n",
    "    m_comb = pd.DataFrame(np.where(m_f1 == 0, m_f2, m_f1), index = cl_id, columns=gene_id)\n",
    "    \n",
    "    return(m_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1bb1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_genes(file, thresh = 0.1):\n",
    "    \"\"\"\n",
    "    thresh: at least ## of cell lines are mutated and are kept. \n",
    "    input: list of dataframes of mutated genes.\n",
    "    output: list of most mutated genes. \n",
    "    \"\"\"\n",
    "    gene_bool = file.apply(lambda x: True if (x == 1).sum()/len(x) >= thresh else False).values\n",
    "    return(file.columns[gene_bool])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83b40ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def EN_cv_in(x_train, y_train, fold, alpha, l1_ratio):\n",
    "        \"\"\"\n",
    "        input: training set. (each alpha, l1_ratio parameter)\n",
    "        output: averge spearman correlation score of 10 results\n",
    "        \"\"\"\n",
    "        #alpha = p1, l1_ratio = p2\n",
    "        kf_in = KFold(n_splits = fold)\n",
    "        cv_perf = np.array([]) \n",
    "        for train_in, test_in in kf_in.split(x_train):\n",
    "\n",
    "            x_train_in, x_test_in, y_train_in, y_test_in = x_train[train_in], x_train[test_in], y_train[train_in], y_train[test_in]\n",
    "\n",
    "            #build model with each combination of parameters. \n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter('ignore')\n",
    "                regr = ElasticNet(random_state = 0, alpha= alpha, l1_ratio=l1_ratio, fit_intercept = False)\n",
    "                regr.fit(x_train_in, y_train_in)\n",
    "                \n",
    "            y_pre = regr.predict(x_test_in)\n",
    "            #perforamance matrix of the model is the Pearson's corrlation coeeficient r. \n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter('ignore')\n",
    "                r = pd.Series(y_pre).corr(pd.Series(y_test_in), method = 'spearman')\n",
    "                cv_perf = np.append(cv_perf,[r])\n",
    "                del regr\n",
    "        return(np.mean(cv_perf))\n",
    "\n",
    "    \n",
    "def out_loop (x, y_total, cl_id, out_cv_fold= 5):\n",
    "    ''' 5 fold cv (outter-loop)\n",
    "    # x: (#_(80%)C, #_genes); y: (#_(80%)C,)\n",
    "    '''\n",
    "    kf = KFold(n_splits = out_cv_fold)\n",
    "    pre_y_array = dict(list(zip(cl_id,[ [] for _ in range(len(cl_id))])))\n",
    "    per_test_list = []\n",
    "    for train, test in kf.split(x):\n",
    "        x_train, x_test, y_train, y_test = x.values[train], x.values[test], y_total.values[train], y_total.values[test]\n",
    "        train_label, test_label = x.index[train], x.index[test]\n",
    "        # 10-fold in x_train (inner-loop). \n",
    "        # each pair of alpha and l1_ratio, do cross training to sellect best pair. \n",
    "\n",
    "        l1_ratio_list = np.linspace(start = 0.2, stop = 1.0, num = 10) #10 values\n",
    "        alpha_list =  np.array([math.exp(i) for i in np.arange(-16,5,2)]) # 250 values\n",
    "        #alpha_list =  np.array([math.exp(i) for i in np.arange(-8,5,0.8)]) #  values\n",
    "        para_matrix = {(l1_ratio, alpha):0 for l1_ratio in l1_ratio_list for alpha in alpha_list}\n",
    "\n",
    "        for (l1_ratio, alpha) in para_matrix:\n",
    "            #do ten fold cv to sellect best parameter pairs. \n",
    "            ave_per = EN_cv_in(x_train= x_train, y_train = y_train, fold = 10, alpha = alpha, l1_ratio= l1_ratio)\n",
    "            para_matrix[(l1_ratio, alpha)] = ave_per\n",
    "        print(para_matrix)\n",
    "        \n",
    "        #return the best alpha-l1-ratio pair.\n",
    "        op_l1_ratio, op_alpha = pd.Series(para_matrix).idxmax() \n",
    "        print('the best validation performance is: ', para_matrix[(op_l1_ratio, op_alpha)])\n",
    "        \n",
    "        #predict on the 5th-fold set (testing set)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            regr = ElasticNet(random_state=0, alpha= op_alpha, l1_ratio = l1_ratio, fit_intercept = False)\n",
    "            regr.fit(x_train, y_train)\n",
    "            y_pre = regr.predict(x_test)\n",
    "            \n",
    "        if len(np.unique(y_pre) ) == 1: print('constant prediction.')\n",
    "        del regr\n",
    "        #add results to the storage dictionary. \n",
    "        for index, value in zip(test_label, y_pre): pre_y_array[index].append(value)\n",
    "        per_test = pd.Series(y_pre).corr(pd.Series(y_test),method = 'spearman') \n",
    "        per_test_list.append(per_test)\n",
    "        print('performance on the test set is:', per_test)\n",
    "        plt.scatter(y_test, y_pre)\n",
    "        plt.xlabel('test set')\n",
    "        plt.ylabel('prediction')\n",
    "        plt.show()\n",
    "        #break\n",
    "    #add the prediction to the list.\n",
    "    pre_y_array = pd.Series(pre_y_array).reindex(cl_id)\n",
    "    \n",
    "    return(pre_y_array, per_test_list)\n",
    "\n",
    "def drug_model(comp_index, m_file,  drug_data, out_path):\n",
    "    \"\"\"\n",
    "    input: m_file mutation matrix with unpreprocessed binery values.\n",
    "    output: mean prediction values of 10 iterations in pd.Sereis type.\n",
    "    \"\"\"\n",
    "    #eliminate cell lines with nan dryg sensitivity data.\n",
    "    #comp_index = 0\n",
    "#     print(comp_index)\n",
    "#     print(m_file.shape)\n",
    "    \n",
    "    valid_cl_index = drug_data.loc[m_file.index,:].iloc[:,comp_index].dropna().index\n",
    "    Y = drug_data.iloc[:, comp_index][valid_cl_index]\n",
    "    drug_name = drug_data.columns[comp_index]\n",
    "    print('drug_name is: ',drug_name)\n",
    "    print('number of missing values in Y: ', Y.isnull().sum())\n",
    "    m_file_notna = m_file.loc[valid_cl_index,:]\n",
    "    \n",
    "    #normalize the each col to have ~0 mean and ~1 sd. \n",
    "    norm_m_file = (m_file_notna - m_file_notna.mean(axis = 0)) / m_file_notna.std(axis = 0)\n",
    "    print(norm_m_file.sum())\n",
    "    \n",
    "    print('### normalize with mean=0, std = 1.')\n",
    "    norm_m_file.dropna(axis = 1, inplace = True)\n",
    "    \n",
    "#     #Use features that have pearson correlation with Y over 0.1.\n",
    "#     cor_number = norm_m_file.corrwith(Y, axis = 0, method = 'pearson')\n",
    "#     #number of genes that have correlation over 0.1\n",
    "#     #sum(np.abs(cor_number) >= 0.1)\n",
    "#     norm_m_file = norm_m_file.loc[:, np.abs(cor_number) >= 0.1]\n",
    "#     #print('number of features selected {}'.format(sum(np.abs(cor_number) >= 0.1)))\n",
    "    \n",
    "    \n",
    "    print('number of features selected {}'.format(norm_m_file.shape[1]))\n",
    "    X, Y_total = norm_m_file, Y\n",
    "    \n",
    "    ### EN model\n",
    "    ## bootstraping (80% of data) for 10 times. \n",
    "    ## each time with 80% data for training, 10% for cross validataion, and remaining 10% for\n",
    "    ## testing.\n",
    "    cl_id = norm_m_file.index\n",
    "    Y_pre_array = pd.Series(dict(list(zip(cl_id, [[] for i in range(cl_id.shape[0])]))),\n",
    "                            index = cl_id, name = drug_name)\n",
    "    cv_result_list = []\n",
    "    for i in tqdm(range(10)):\n",
    "        print('iteration {} begains'.format(i))\n",
    "        x, y_total = resample(X, Y_total, replace = False, n_samples = int(X.shape[0]*0.8), random_state = i)\n",
    "        print(X.isna().sum().sum())\n",
    "        print(y_total.isna().sum().sum())\n",
    "\n",
    "        #outter loop with 5 fold cv.\n",
    "        prediction, cv_list = out_loop(x = x, y_total= y_total, cl_id = cl_id, out_cv_fold=5 )\n",
    "        cv_result_list.extend(cv_list)\n",
    "        print('iter {}, outter loop finished. '.format(i))\n",
    "        \n",
    "        for i in prediction.index: Y_pre_array[i].extend(prediction[i])\n",
    "\n",
    "    \n",
    "    ##calculate the mean of 10 iterations. \n",
    "    Y_pre_array = Y_pre_array.map(np.mean)\n",
    "    tools.write_file(Y_pre_array, 'comp_{}.csv'.format(comp_index), out_path)\n",
    "    # list of cross validation results. \n",
    "    return(cv_result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16a8d303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### reading files completed\n"
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "#read data\n",
    "drug_data = read_drug(drug_path = drug_path)\n",
    "m_f1, m_f2, m_f3,_  = file_list\n",
    "m_f1 = pd.read_csv(path + 'CCLE_mutations_bool_' + m_f1 + '.csv', index_col = 0)\n",
    "m_f2 = pd.read_csv(path + 'CCLE_mutations_bool_' + m_f2 + '.csv', index_col = 0)\n",
    "m_f3 = pd.read_csv(path + 'CCLE_mutations_bool_' + m_f3 + '.csv', index_col = 0)\n",
    "print('#### reading files completed')\n",
    "\n",
    "#merge mutation files\n",
    "m_file = merge_mt(merge_mt(m_f1, m_f2, drug_id=drug_data.index), m_f3, \n",
    "                  drug_id= drug_data.index,gene_filter=False)\n",
    "#m_file = m_f1.reindex(set.intersection(set(m_f1.index), set(drug_data.index)))\n",
    "print('#### merge mutation files completed')\n",
    "print(m_file.shape)\n",
    "#filter most mutated genes. \n",
    "w_m_file = merge_mt(merge_mt(m_f1, m_f2, drug_id=drug_data.index, gene_filter=True), m_f3, \n",
    "                  drug_id= drug_data.index,gene_filter = True)\n",
    "\n",
    "#w_m_file = m_f1\n",
    "#m_file = m_f1\n",
    "gene_bool = filter_genes(w_m_file, thresh=0.08)\n",
    "#print(gene_bool)\n",
    "m_file = m_file.loc[:,gene_bool]\n",
    "print(m_file.shape)\n",
    "\n",
    "# get rid of drugs with too many missing values.\n",
    "thresh  = int(m_file.shape[0]*(1-0.1)) ## at least ## number of Non-na value in each drug\n",
    "drug_id_list = drug_data.loc[m_file.index,:].dropna(axis = 1, thresh = thresh).columns\n",
    "#build model for each drug.\n",
    "pre_matrix = pd.Series(index = m_file.index)\n",
    "\n",
    "''' multiprocessing the command '''\n",
    "n_jobs = 100\n",
    "jobs_list = tools.split_task(len(drug_id_list), n_jobs)\n",
    "drug_mapping_list = list(zip(drug_id_list, [np.where(drug_data.columns == drug_id)\n",
    "for index_array in jobs_list:\n",
    "    work_list = []\n",
    "    for job in index_array:\n",
    "        drug_name, drug_index = drug_mapping_list[job][0], int(drug_mapping_list[job][1][0])\n",
    "        p = multiprocessing.Process(target = drug_model, args = (drug_index, m_file, drug_data))\n",
    "        work_list.append(p)\n",
    "    #start the programs.\n",
    "    for job in work_list: job.start()\n",
    "    #end the programs.\n",
    "    for job in work_list: job.join()\n",
    "\n",
    "# for index, (drug_name, drug_index) in enumerate(list(zip(drug_id_list, [np.where(drug_data.columns == drug_id) for drug_id in drug_id_list]))):\n",
    "#     if index == 3:\n",
    "#         result = drug_model(comp_index = int(drug_index[0]), m_file = m_file, drug_data=drug_data,\n",
    "#                        out_path= out_path)\n",
    "#     #pre_matrix = pd.concat([pre_matrix, result], axis = 1)\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65141d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
